{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want to access the version you have already modified, click \"Edit\"\n",
    "## If you want to access the original sample code, click \"...\", then click \"Copy & Edit Notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 19.351342,
     "end_time": "2022-02-23T10:03:06.247288",
     "exception": false,
     "start_time": "2022-02-23T10:02:46.895946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "```python\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "```\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "```python\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        pass\n",
    "        #print(os.path.join(dirname, filename))\n",
    "```\n",
    "## **You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" **\n",
    "## **You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 25 18:11:07 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.74       Driver Version: 470.74       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M4000        Off  | 00000000:04:00.0  On |                  N/A |\n",
      "| 51%   55C    P0    46W / 120W |   1805MiB /  8123MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1690      G   /usr/lib/xorg/Xorg                264MiB |\n",
      "|    0   N/A  N/A      2293      G   /usr/bin/gnome-shell               44MiB |\n",
      "|    0   N/A  N/A     74871      G   ...AAAAAAAAA= --shared-files       74MiB |\n",
      "|    0   N/A  N/A    681402      C   ...3/envs/pytorch/bin/python     1333MiB |\n",
      "|    0   N/A  N/A   2669200      G   ...AAAAAAAAA= --shared-files       22MiB |\n",
      "|    0   N/A  N/A   4003949      C   ...ffice/program/soffice.bin       54MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.0189,
     "end_time": "2022-02-23T10:03:06.279758",
     "exception": false,
     "start_time": "2022-02-23T10:03:06.260858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_exp_name = \"sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 1.654263,
     "end_time": "2022-02-23T10:03:07.947242",
     "exception": false,
     "start_time": "2022-02-23T10:03:06.292979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "\n",
    "# This is for the progress bar.\n",
    "from tqdm.auto import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.078771,
     "end_time": "2022-02-23T10:03:08.039428",
     "exception": false,
     "start_time": "2022-02-23T10:03:07.960657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "myseed = 6666  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01289,
     "end_time": "2022-02-23T10:03:08.065357",
     "exception": false,
     "start_time": "2022-02-23T10:03:08.052467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Transforms**\n",
    "Torchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.\n",
    "\n",
    "Please refer to PyTorch official website for details about different transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.021406,
     "end_time": "2022-02-23T10:03:08.099437",
     "exception": false,
     "start_time": "2022-02-23T10:03:08.078031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normally, We don't need augmentations in testing and validation.\n",
    "# All we need here is to resize the PIL image and transform it into Tensor.\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# However, it is also possible to use augmentation in the testing phase.\n",
    "# You may use train_tfm to produce a variety of images and then test using ensemble methods\n",
    "train_tfm = transforms.Compose([\n",
    "    # Resize the image into a fixed shape (height = width = 128)\n",
    "    #transforms.CenterCrop()\n",
    "    transforms.RandomResizedCrop((128, 128), scale=(0.7, 1.0)),\n",
    "    #transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
    "    #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.RandomRotation(180),\n",
    "    transforms.RandomAffine(30),\n",
    "    #transforms.RandomInvert(p=0.2),\n",
    "    #transforms.RandomPosterize(bits=2),\n",
    "    #transforms.RandomSolarize(threshold=192.0, p=0.2),\n",
    "    #transforms.RandomEqualize(p=0.2),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.RandomApply(torch.nn.ModuleList([]))\n",
    "    # You may add some transforms here.\n",
    "    # ToTensor() should be the last one of the transforms.\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012739,
     "end_time": "2022-02-23T10:03:08.125181",
     "exception": false,
     "start_time": "2022-02-23T10:03:08.112442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Datasets**\n",
    "The data is labelled by the name, so we load images and label while calling '__getitem__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.023022,
     "end_time": "2022-02-23T10:03:08.160912",
     "exception": false,
     "start_time": "2022-02-23T10:03:08.13789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "\n",
    "    def __init__(self,path=None,tfm=test_tfm,files=None):\n",
    "        super(FoodDataset).__init__()\n",
    "        self.path = path\n",
    "        if path:\n",
    "            self.files = sorted([os.path.join(path, x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n",
    "        else:\n",
    "            self.files = files\n",
    "        self.transform = tfm\n",
    "        print('Num of element: ', len(self.files))\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        fname = self.files[idx]\n",
    "        im = Image.open(fname)\n",
    "        im = self.transform(im)\n",
    "        #im = self.data[idx]\n",
    "        try:\n",
    "            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n",
    "        except:\n",
    "            label = -1 # test has no label\n",
    "        return im,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.0258,
     "end_time": "2022-02-23T10:03:08.199437",
     "exception": false,
     "start_time": "2022-02-23T10:03:08.173637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#class Classifier(nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super(Classifier, self).__init__()\n",
    "#        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "#        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "#        # input 維度 [3, 128, 128]\n",
    "#        self.cnn = nn.Sequential(\n",
    "#            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n",
    "#            nn.BatchNorm2d(64),\n",
    "#            nn.ReLU(),\n",
    "#            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64] \n",
    "#           \n",
    "#\n",
    "#            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n",
    "#            nn.BatchNorm2d(128),\n",
    "#            nn.ReLU(),\n",
    "#            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n",
    "#          \n",
    "#            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n",
    "#            nn.BatchNorm2d(256),\n",
    "#            nn.ReLU(),\n",
    "#            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n",
    "#\n",
    "#            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n",
    "#            nn.BatchNorm2d(512),\n",
    "#            nn.ReLU(),\n",
    "#            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n",
    "#            \n",
    "#            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "#            nn.BatchNorm2d(512),\n",
    "#            nn.ReLU(),  \n",
    "#            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n",
    "#        )\n",
    "#        self.fc = nn.Sequential(\n",
    "#            nn.Dropout(0.4),\n",
    "#            nn.Linear(512*4*4, 1024),\n",
    "#            nn.ReLU(),\n",
    "#            nn.Linear(1024, 512),\n",
    "#            nn.ReLU(),\n",
    "#            nn.Linear(512, 11)\n",
    "#        )\n",
    "#\n",
    "#    def forward(self, x):\n",
    "#        out = self.cnn(x)\n",
    "#        out = out.view(out.size()[0], -1)\n",
    "#        return self.fc(out)\n",
    "\n",
    "class Residual_Block(nn.Module):\n",
    "    def __init__(self, ic, oc, stride=1):\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(ic, oc, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(oc),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(oc, oc, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(oc),\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "        self.downsample = None\n",
    "        if stride != 1 or (ic != oc):\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(ic, oc, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(oc),\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "            \n",
    "        out += residual\n",
    "        return self.relu(out)\n",
    "        \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, block, num_layers, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.preconv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.layer0 = self.make_residual(block, 32, 64,  num_layers[0], stride=2)\n",
    "        self.layer1 = self.make_residual(block, 64, 128, num_layers[1], stride=2)\n",
    "        self.layer2 = self.make_residual(block, 128, 256, num_layers[2], stride=2)\n",
    "        self.layer3 = self.make_residual(block, 256, 512, num_layers[3], stride=2)\n",
    "        \n",
    "        #self.avgpool = nn.AvgPool2d(2)\n",
    "        \n",
    "        self.fc = nn.Sequential(            \n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512*4*4, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 11),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def make_residual(self, block, ic, oc, num_layer, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(ic, oc, stride))\n",
    "        for i in range(1, num_layer):\n",
    "            layers.append(block(oc, oc))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # [3, 128, 128]\n",
    "        out = self.preconv(x)  # [32, 64, 64]\n",
    "        out = self.layer0(out) # [64, 32, 32]\n",
    "        out = self.layer1(out) # [128, 16, 16]\n",
    "        out = self.layer2(out) # [256, 8, 8]\n",
    "        out = self.layer3(out) # [512, 4, 4]\n",
    "        #out = self.avgpool(out) # [512, 2, 2]\n",
    "        out = self.fc(out.view(out.size(0), -1)) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, class_num, alpha=None, gamma=2, size_average=True):\n",
    "        super().__init__()\n",
    "        if alpha is None:\n",
    "            self.alpha = Variable(torch.ones(class_num, 1))\n",
    "        else:\n",
    "            if isinstance(alpha, Variable):\n",
    "                self.alpha = alpha\n",
    "            else:\n",
    "                self.alpha = Variable(alpha)\n",
    "        self.gamma = gamma\n",
    "        self.class_num = class_num\n",
    "        self.size_average = size_average\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        N = inputs.size(0)\n",
    "        C = inputs.size(1)\n",
    "        P = F.softmax(inputs, dim=1)\n",
    "        \n",
    "        class_mask = inputs.data.new(N, C).fill_(0)\n",
    "        class_mask = Variable(class_mask)\n",
    "        ids = targets.view(-1, 1)\n",
    "        class_mask.scatter_(1, ids.data, 1.)\n",
    "        \n",
    "        if inputs.is_cuda and not self.alpha.is_cuda:\n",
    "            self.alpha = self.alpha.cuda()\n",
    "        alpha = self.alpha[ids.data.view(-1)]\n",
    "        probs = (P*class_mask).sum(1).view(-1, 1)\n",
    "        \n",
    "        log_p = probs.log()\n",
    "        \n",
    "        batch_loss = -alpha*(torch.pow((1-probs), self.gamma))*log_p\n",
    "        \n",
    "        if self.size_average:\n",
    "            loss = batch_loss.mean()\n",
    "        else:\n",
    "            loss = batch_loss.sum()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "class MyCrossEntropy(nn.Module):\n",
    "    def __init__(self, class_num):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_layers = [2, 4, 3, 1] # residual number layers\n",
    "alpha = torch.Tensor([1, 2.3, 0.66, 1, 1.1, 0.75, 2.3, 3.5, 1.1, 0.66, 1.4])\n",
    "\n",
    "n_epochs = 300\n",
    "patience = 32 # If no improvement in 'patience' epochs, early stop\n",
    "\n",
    "k_fold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"ml2022spring-hw3b/food11/training\"\n",
    "val_dir = \"ml2022spring-hw3b/food11/validation\"\n",
    "\n",
    "train_files = [os.path.join(train_dir, x) for x in os.listdir(train_dir) if x.endswith('.jpg')]\n",
    "val_files = [os.path.join(val_dir, x) for x in os.listdir(val_dir) if x.endswith('.jpg')]\n",
    "total_files = train_files + val_files\n",
    "random.shuffle(total_files)\n",
    "\n",
    "num = len(total_files) // k_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 32830.720158,
     "end_time": "2022-02-23T19:10:19.001001",
     "exception": false,
     "start_time": "2022-02-23T10:03:08.280843",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"cuda\" only when GPUs are available.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# The number of training epochs and patience.\n",
    "\n",
    "\n",
    "# Initialize a model, and put it on the device specified.\n",
    "\n",
    "#from torchsummary import summary\n",
    "#summary(model, (3, 128, 128))\n",
    "# For the classification task, we use cross-entropy as the measurement of performance.\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n",
    "\n",
    "# Initialize trackers, these are not parameters and should not be changed\n",
    "\n",
    "test_fold = k_fold\n",
    "\n",
    "for i in range(test_fold):\n",
    "    fold = i+1\n",
    "    print(f'\\n\\nStarting Fold: {fold} ********************************************')\n",
    "    model = Classifier(Residual_Block, num_layers).to(device)\n",
    "    criterion = FocalLoss(11, alpha=alpha)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0004, weight_decay=2e-5) \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=16, T_mult=1)\n",
    "    stale = 0\n",
    "    best_acc = 0\n",
    "    \n",
    "    val_data = total_files[i*num: (i+1)*num]\n",
    "    train_data = total_files[:i*num] + total_files[(i+1)*num:]\n",
    "    \n",
    "    train_set = FoodDataset(tfm=train_tfm, files=train_data)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    valid_set = FoodDataset(tfm=test_tfm, files=val_data)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "    \n",
    "        # ---------- Training ----------\n",
    "        # Make sure the model is in train mode before training.\n",
    "        model.train()\n",
    "    \n",
    "        # These are used to record information in training.\n",
    "        train_loss = []\n",
    "        train_accs = []\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        \n",
    "        pbar = tqdm(train_loader)\n",
    "        pbar.set_description(f'T: {epoch+1:03d}/{n_epochs:03d}')\n",
    "        for batch in pbar:\n",
    "    \n",
    "            # A batch consists of image data and corresponding labels.\n",
    "            imgs, labels = batch\n",
    "            #imgs = imgs.half()\n",
    "            #print(imgs.shape,labels.shape)\n",
    "    \n",
    "            # Forward the data. (Make sure data and model are on the same device.)\n",
    "            logits = model(imgs.to(device))\n",
    "    \n",
    "            # Calculate the cross-entropy loss.\n",
    "            # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n",
    "            loss = criterion(logits, labels.to(device))\n",
    "    \n",
    "            # Gradients stored in the parameters in the previous step should be cleared out first.\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # Compute the gradients for parameters.\n",
    "            loss.backward()\n",
    "    \n",
    "            # Clip the gradient norms for stable training.\n",
    "            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "    \n",
    "            # Update the parameters with computed gradients.\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Compute the accuracy for current batch.\n",
    "            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "    \n",
    "            # Record the loss and accuracy.\n",
    "            train_loss.append(loss.item())\n",
    "            train_accs.append(acc)\n",
    "            pbar.set_postfix({'lr':lr, 'b_loss':loss.item(), 'b_acc':acc.item(),\n",
    "                    'loss':sum(train_loss)/len(train_loss), 'acc': sum(train_accs).item()/len(train_accs)})\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "        # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
    "        model.eval()\n",
    "    \n",
    "        # These are used to record information in validation.\n",
    "        valid_loss = []\n",
    "        valid_accs = []\n",
    "    \n",
    "        # Iterate the validation set by batches.\n",
    "        pbar = tqdm(valid_loader)\n",
    "        pbar.set_description(f'V: {epoch+1:03d}/{n_epochs:03d}')\n",
    "        for batch in pbar:\n",
    "\n",
    "            # A batch consists of image data and corresponding labels.\n",
    "            imgs, labels = batch\n",
    "            #imgs = imgs.half()\n",
    "    \n",
    "            # We don't need gradient in validation.\n",
    "            # Using torch.no_grad() accelerates the forward process.\n",
    "            with torch.no_grad():\n",
    "                logits = model(imgs.to(device))\n",
    "    \n",
    "            # We can still compute the loss (but not the gradient).\n",
    "            loss = criterion(logits, labels.to(device))\n",
    "    \n",
    "            # Compute the accuracy for current batch.\n",
    "            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "    \n",
    "            # Record the loss and accuracy.\n",
    "            valid_loss.append(loss.item())\n",
    "            valid_accs.append(acc)\n",
    "            pbar.set_postfix({'v_loss':sum(valid_loss)/len(valid_loss), \n",
    "                              'v_acc': sum(valid_accs).item()/len(valid_accs)})\n",
    "        \n",
    "            #break\n",
    "    \n",
    "        # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "        valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "        valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "    \n",
    "    \n",
    "        if valid_acc > best_acc:\n",
    "            print(f\"Best model found at fold {fold} epoch {epoch+1}, acc={valid_acc:.5f}, saving model\")\n",
    "            torch.save(model.state_dict(), f\"Fold_{fold}_best.ckpt\")\n",
    "            # only save best to prevent output memory exceed error\n",
    "            best_acc = valid_acc\n",
    "            stale = 0\n",
    "        else:\n",
    "            stale += 1\n",
    "            if stale > patience:\n",
    "                print(f\"No improvment {patience} consecutive epochs, early stopping\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.493644,
     "end_time": "2022-02-23T19:10:19.985992",
     "exception": false,
     "start_time": "2022-02-23T19:10:19.492348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of element:  3347\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"ml2022spring-hw3b/food11/test\"\n",
    "test_set = FoodDataset(test_dir, tfm=test_tfm)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_tfm1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m test_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mml2022spring-hw3b/food11/test\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m test_tfms \u001b[39m=\u001b[39m [test_tfm1, test_tfm2, test_tfm3, test_tfm4, test_tfm5]\n\u001b[0;32m      3\u001b[0m test_loaders \u001b[39m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_tfm1' is not defined"
     ]
    }
   ],
   "source": [
    "test_dir = \"ml2022spring-hw3b/food11/test\"\n",
    "test_tfms = [test_tfm1, test_tfm2, test_tfm3, test_tfm4, test_tfm5]\n",
    "test_loaders = []\n",
    "for i in range(5):\n",
    "    test_set_i = FoodDataset(test_dir, tfm=train_tfm)\n",
    "    test_loader_i = DataLoader(test_set_i, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    test_loaders.append(test_loader_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.498773,
     "end_time": "2022-02-23T19:10:20.961802",
     "exception": false,
     "start_time": "2022-02-23T19:10:20.463029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing and generate prediction CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 49.157727,
     "end_time": "2022-02-23T19:11:10.61523",
     "exception": false,
     "start_time": "2022-02-23T19:10:21.457503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "(6, 3347, 11)\n",
      "(3347, 11)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "models = []\n",
    "for i in range(0, 4):\n",
    "    fold = i + 1\n",
    "    model_best = Classifier(Residual_Block, num_layers).to(device)\n",
    "    model_best.load_state_dict(torch.load(f\"Fold_{fold}_best.ckpt\"))\n",
    "    model_best.eval()\n",
    "    models.append(model_best)\n",
    "\n",
    "preds = [[], [], [], [], [], []] \n",
    "with torch.no_grad():\n",
    "    for data, _ in test_loader:\n",
    "        batch_preds = [] \n",
    "        for model_best in models:\n",
    "            batch_preds.append(model_best(data.to(device)).cpu().data.numpy())\n",
    "        batch_preds = sum(batch_preds)\n",
    "        preds[0].extend(batch_preds.squeeze().tolist())\n",
    "        \n",
    "        #batch_label = np.argmax(batch_preds, axis=1)\n",
    "        #prediction += batch_label.squeeze().tolist()\n",
    "        \n",
    "    for i, loader in enumerate(test_loaders):\n",
    "        for data, _ in loader:\n",
    "            batch_preds = []\n",
    "            for model_best in models:\n",
    "                batch_preds.append(model_best(data.to(device)).cpu().data.numpy())\n",
    "            batch_preds = sum(batch_preds)\n",
    "            preds[i+1].extend(batch_preds.squeeze().tolist())\n",
    "\n",
    "preds = np.array(preds)\n",
    "print(preds.shape)\n",
    "preds = 0.6* preds[0] + 0.1 * preds[1] + 0.1 * preds[2] + 0.1 * preds[3] + 0.1 * preds[4] + 0.1 * preds[5]\n",
    "print(preds.shape)\n",
    "prediction = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "papermill": {
     "duration": 0.554276,
     "end_time": "2022-02-23T19:11:11.870035",
     "exception": false,
     "start_time": "2022-02-23T19:11:11.315759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create test csv\n",
    "import pandas as pd\n",
    "def pad4(i):\n",
    "    return \"0\"*(4-len(str(i)))+str(i)\n",
    "df = pd.DataFrame()\n",
    "df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n",
    "df[\"Category\"] = prediction\n",
    "df.to_csv(\"submission.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
