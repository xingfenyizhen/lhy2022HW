{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fde246d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-20T14:34:00.748547Z",
     "iopub.status.busy": "2022-03-20T14:34:00.747070Z",
     "iopub.status.idle": "2022-03-20T14:34:07.226314Z",
     "shell.execute_reply": "2022-03-20T14:34:07.225560Z",
     "shell.execute_reply.started": "2022-03-20T04:53:00.300329Z"
    },
    "papermill": {
     "duration": 6.499474,
     "end_time": "2022-03-20T14:34:07.226486",
     "exception": false,
     "start_time": "2022-03-20T14:34:00.727012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        pass\n",
    "        #print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b70f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T14:34:07.278166Z",
     "iopub.status.busy": "2022-03-20T14:34:07.277140Z",
     "iopub.status.idle": "2022-03-20T14:34:08.706850Z",
     "shell.execute_reply": "2022-03-20T14:34:08.706032Z",
     "shell.execute_reply.started": "2022-03-20T04:53:04.504953Z"
    },
    "papermill": {
     "duration": 1.464677,
     "end_time": "2022-03-20T14:34:08.706999",
     "exception": false,
     "start_time": "2022-03-20T14:34:07.242322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_feat(path):\n",
    "    feat = torch.load(path)\n",
    "    return feat\n",
    "\n",
    "def shift(x, n):\n",
    "    if n < 0:\n",
    "        left = x[0].repeat(-n, 1)\n",
    "        right = x[:n]\n",
    "\n",
    "    elif n > 0:\n",
    "        right = x[-1].repeat(n, 1)\n",
    "        left = x[n:]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    return torch.cat((left, right), dim=0)\n",
    "\n",
    "def concat_feat(x, concat_n):\n",
    "    assert concat_n % 2 == 1 # n must be odd\n",
    "    if concat_n < 2:\n",
    "        return x\n",
    "    seq_len, feature_dim = x.size(0), x.size(1)\n",
    "    x = x.repeat(1, concat_n) \n",
    "    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n",
    "    mid = (concat_n // 2)\n",
    "    for r_idx in range(1, mid+1):\n",
    "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
    "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
    "\n",
    "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
    "\n",
    "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, train_val_seed=1337):\n",
    "    class_num = 41 # NOTE: pre-computed, should not need change\n",
    "    mode = 'train' if (split == 'train' or split == 'val') else 'test'\n",
    "\n",
    "    label_dict = {}\n",
    "    if mode != 'test':\n",
    "      phone_file = open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines()\n",
    "\n",
    "      for line in phone_file:\n",
    "          line = line.strip('\\n').split(' ')\n",
    "          label_dict[line[0]] = [int(p) for p in line[1:]]\n",
    "\n",
    "    if split == 'train' or split == 'val':\n",
    "        # split training and validation data\n",
    "        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
    "        random.seed(train_val_seed)\n",
    "        random.shuffle(usage_list)\n",
    "        percent = int(len(usage_list) * train_ratio)\n",
    "        usage_list = usage_list[:percent] if split == 'train' else usage_list[percent:]\n",
    "    elif split == 'test':\n",
    "        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
    "    else:\n",
    "        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
    "\n",
    "    usage_list = [line.strip('\\n') for line in usage_list]\n",
    "    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
    "\n",
    "    max_len = 3000000\n",
    "    X = torch.empty(max_len, 39 * concat_nframes)\n",
    "    if mode != 'test':\n",
    "      y = torch.empty(max_len, concat_nframes, dtype=torch.long)\n",
    "\n",
    "    idx = 0\n",
    "    for i, fname in tqdm(enumerate(usage_list)):\n",
    "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
    "        cur_len = len(feat)\n",
    "        feat = concat_feat(feat, concat_nframes)\n",
    "        if mode != 'test':\n",
    "          label = torch.LongTensor(label_dict[fname]).unsqueeze(1)\n",
    "          label = concat_feat(label, concat_nframes)\n",
    "\n",
    "        X[idx: idx + cur_len, :] = feat\n",
    "        if mode != 'test':\n",
    "          y[idx: idx + cur_len] = label\n",
    "\n",
    "        idx += cur_len\n",
    "\n",
    "    X = X[:idx, :]\n",
    "    if mode != 'test':\n",
    "      y = y[:idx]\n",
    "\n",
    "    print(f'[INFO] {split} set')\n",
    "    print(X.shape)\n",
    "    if mode != 'test':\n",
    "      print(y.shape)\n",
    "      return X, y\n",
    "    else:\n",
    "      return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1ed59e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T14:34:08.743674Z",
     "iopub.status.busy": "2022-03-20T14:34:08.742827Z",
     "iopub.status.idle": "2022-03-20T14:34:08.744605Z",
     "shell.execute_reply": "2022-03-20T14:34:08.745055Z",
     "shell.execute_reply.started": "2022-03-20T04:53:04.529331Z"
    },
    "papermill": {
     "duration": 0.023225,
     "end_time": "2022-03-20T14:34:08.745185",
     "exception": false,
     "start_time": "2022-03-20T14:34:08.721960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class LibriDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.data = X\n",
    "        if y is not None:\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx].view(-1, 39), self.label[idx]\n",
    "        else:\n",
    "            return self.data[idx].view(-1, 39)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1bc8624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T14:34:08.778835Z",
     "iopub.status.busy": "2022-03-20T14:34:08.778075Z",
     "iopub.status.idle": "2022-03-20T14:34:18.337250Z",
     "shell.execute_reply": "2022-03-20T14:34:18.336445Z",
     "shell.execute_reply.started": "2022-03-20T04:53:04.541997Z"
    },
    "papermill": {
     "duration": 9.57765,
     "end_time": "2022-03-20T14:34:18.337381",
     "exception": false,
     "start_time": "2022-03-20T14:34:08.759731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-crf\r\n",
      "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\r\n",
      "Installing collected packages: pytorch-crf\r\n",
      "Successfully installed pytorch-crf-0.7.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3240be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T14:34:18.381359Z",
     "iopub.status.busy": "2022-03-20T14:34:18.380556Z",
     "iopub.status.idle": "2022-03-20T14:34:18.386557Z",
     "shell.execute_reply": "2022-03-20T14:34:18.386991Z",
     "shell.execute_reply.started": "2022-03-20T04:53:14.058824Z"
    },
    "papermill": {
     "duration": 0.033266,
     "end_time": "2022-03-20T14:34:18.387126",
     "exception": false,
     "start_time": "2022-03-20T14:34:18.353860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchcrf import CRF\n",
    "\n",
    "\n",
    "#class BiLSTM_CRF(nn.Module):\n",
    "#\n",
    "#    def __init__(self, class_size=41, input_dim=39, hidden_dim=128,dropout=0.5):\n",
    "#        super().__init__()\n",
    "#        self.input_dim = input_dim\n",
    "#        self.hidden_dim = hidden_dim\n",
    "#        self.class_size = class_size\n",
    "#\n",
    "#        self.lstm = nn.LSTM(input_dim, hidden_dim // 2, dropout=dropout,\n",
    "#                            num_layers=3, bidirectional=True, batch_first=True)\n",
    "#        self.hidden2tag = nn.Sequential(\n",
    "#            nn.Dropout(dropout),\n",
    "#            nn.Linear(hidden_dim, class_size)\n",
    "#        )\n",
    "#\n",
    "#        self.crf = CRF(self.class_size, batch_first=True)\n",
    "#        \n",
    "#    def get_emissions(self, x):\n",
    "#        feats, _ = self.lstm(x)\n",
    "#        return self.hidden2tag(feats)\n",
    "#\n",
    "#    def likelihood(self, x, y):\n",
    "#        emissions = self.get_emissions(x)\n",
    "#        loss = self.crf(emissions, y)\n",
    "#        return loss\n",
    "#\n",
    "#    def forward(self, x):  # dont confuse this with _forward_alg above.\n",
    "#        emissions = self.get_emissions(x)\n",
    "#        seqs = self.crf.decode(emissions)\n",
    "#        return torch.LongTensor(seqs)\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, class_size=41, input_dim=39, hidden_dim=192, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.class_size = class_size\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim // 2, dropout=dropout,\n",
    "                            num_layers=3, bidirectional=True, batch_first=True)\n",
    "        self.hidden2tag = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, class_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feats, _ = self.lstm(x)\n",
    "        return self.hidden2tag(feats)\n",
    "    \n",
    "class Crf(nn.Module):\n",
    "    def __init__(self, class_size=41):\n",
    "        super().__init__()\n",
    "        self.class_size = class_size\n",
    "        self.crf = CRF(self.class_size, batch_first=True)\n",
    "        \n",
    "    def likelihood(self, x, y):\n",
    "        return self.crf(x, y)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.LongTensor(self.crf.decode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67f261b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T14:34:18.424272Z",
     "iopub.status.busy": "2022-03-20T14:34:18.423591Z",
     "iopub.status.idle": "2022-03-20T14:34:18.426626Z",
     "shell.execute_reply": "2022-03-20T14:34:18.426203Z",
     "shell.execute_reply.started": "2022-03-20T04:53:14.078701Z"
    },
    "papermill": {
     "duration": 0.023935,
     "end_time": "2022-03-20T14:34:18.426762",
     "exception": false,
     "start_time": "2022-03-20T14:34:18.402827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data prarameters\n",
    "concat_nframes = 21          # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
    "mid = concat_nframes//2\n",
    "train_ratio = 0.95               # the ratio of data used for training, the rest will be used for validation\n",
    "\n",
    "# training parameters\n",
    "seed = 0                        # random seed\n",
    "batch_size = 2048                # batch size\n",
    "num_epoch = 50                   # the number of training epoch\n",
    "early_stopping = 8\n",
    "learning_rate = 0.0001            #learning rate\n",
    "model1_path = './model1.ckpt'     # the path where the checkpoint will be saved\n",
    "model2_path = './model2.ckpt'\n",
    "# model parameters\n",
    "input_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\n",
    "hidden_layers = 3              # the number of hidden layers\n",
    "hidden_dim = 1024              # the hidden dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e490ade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T14:34:18.506629Z",
     "iopub.status.busy": "2022-03-20T14:34:18.505836Z",
     "iopub.status.idle": "2022-03-20T14:34:18.509146Z",
     "shell.execute_reply": "2022-03-20T14:34:18.509736Z",
     "shell.execute_reply.started": "2022-03-20T04:53:14.090074Z"
    },
    "papermill": {
     "duration": 0.067477,
     "end_time": "2022-03-20T14:34:18.509929",
     "exception": false,
     "start_time": "2022-03-20T14:34:18.442452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'DEVICE: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec789ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T14:34:18.548345Z",
     "iopub.status.busy": "2022-03-20T14:34:18.547844Z",
     "iopub.status.idle": "2022-03-20T14:34:18.551577Z",
     "shell.execute_reply": "2022-03-20T14:34:18.551050Z",
     "shell.execute_reply.started": "2022-03-20T04:53:14.145272Z"
    },
    "papermill": {
     "duration": 0.024667,
     "end_time": "2022-03-20T14:34:18.551704",
     "exception": false,
     "start_time": "2022-03-20T14:34:18.527037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#fix seed\n",
    "def same_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f03def3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T14:34:18.589956Z",
     "iopub.status.busy": "2022-03-20T14:34:18.589419Z",
     "iopub.status.idle": "2022-03-20T14:35:05.030655Z",
     "shell.execute_reply": "2022-03-20T14:35:05.031080Z",
     "shell.execute_reply.started": "2022-03-20T04:53:14.154749Z"
    },
    "papermill": {
     "duration": 46.463384,
     "end_time": "2022-03-20T14:35:05.031227",
     "exception": false,
     "start_time": "2022-03-20T14:34:18.567843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] - # phone classes: 41, number of utterances for train: 4071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4071it [00:42, 95.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train set\n",
      "torch.Size([2513163, 819])\n",
      "torch.Size([2513163, 21])\n",
      "[Dataset] - # phone classes: 41, number of utterances for val: 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "215it [00:02, 95.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val set\n",
      "torch.Size([130995, 819])\n",
      "torch.Size([130995, 21])\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# preprocess data\n",
    "train_X, train_y = preprocess_data(split='train', feat_dir='../input/ml2022spring-hw2/libriphone/libriphone/feat', \n",
    "                                   phone_path='../input/ml2022spring-hw2/libriphone/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
    "val_X, val_y = preprocess_data(split='val', feat_dir='../input/ml2022spring-hw2/libriphone/libriphone/feat', \n",
    "                               phone_path='../input/ml2022spring-hw2/libriphone/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
    "\n",
    "# get dataset\n",
    "train_set = LibriDataset(train_X, train_y)\n",
    "val_set = LibriDataset(val_X, val_y)\n",
    "\n",
    "# remove raw feature to save memory\n",
    "del train_X, train_y, val_X, val_y\n",
    "gc.collect()\n",
    "\n",
    "# get dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a25724b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T14:35:05.330842Z",
     "iopub.status.busy": "2022-03-20T14:35:05.330156Z",
     "iopub.status.idle": "2022-03-20T14:35:08.769590Z",
     "shell.execute_reply": "2022-03-20T14:35:08.770133Z",
     "shell.execute_reply.started": "2022-03-20T04:55:55.897984Z"
    },
    "papermill": {
     "duration": 3.592876,
     "end_time": "2022-03-20T14:35:08.770299",
     "exception": false,
     "start_time": "2022-03-20T14:35:05.177423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0     parameter num: 14976     shape: torch.Size([384, 39])\n",
      "Layer: 1     parameter num: 36864     shape: torch.Size([384, 96])\n",
      "Layer: 2     parameter num: 384     shape: torch.Size([384])\n",
      "Layer: 3     parameter num: 384     shape: torch.Size([384])\n",
      "Layer: 4     parameter num: 14976     shape: torch.Size([384, 39])\n",
      "Layer: 5     parameter num: 36864     shape: torch.Size([384, 96])\n",
      "Layer: 6     parameter num: 384     shape: torch.Size([384])\n",
      "Layer: 7     parameter num: 384     shape: torch.Size([384])\n",
      "Layer: 8     parameter num: 73728     shape: torch.Size([384, 192])\n",
      "Layer: 9     parameter num: 36864     shape: torch.Size([384, 96])\n",
      "Layer: 10     parameter num: 384     shape: torch.Size([384])\n",
      "Layer: 11     parameter num: 384     shape: torch.Size([384])\n",
      "Layer: 12     parameter num: 73728     shape: torch.Size([384, 192])\n",
      "Layer: 13     parameter num: 36864     shape: torch.Size([384, 96])\n",
      "Layer: 14     parameter num: 384     shape: torch.Size([384])\n",
      "Layer: 15     parameter num: 384     shape: torch.Size([384])\n",
      "Layer: 16     parameter num: 73728     shape: torch.Size([384, 192])\n",
      "Layer: 17     parameter num: 36864     shape: torch.Size([384, 96])\n",
      "Layer: 18     parameter num: 384     shape: torch.Size([384])\n",
      "Layer: 19     parameter num: 384     shape: torch.Size([384])\n",
      "Layer: 20     parameter num: 73728     shape: torch.Size([384, 192])\n",
      "Layer: 21     parameter num: 36864     shape: torch.Size([384, 96])\n",
      "Layer: 22     parameter num: 384     shape: torch.Size([384])\n",
      "Layer: 23     parameter num: 384     shape: torch.Size([384])\n",
      "Layer: 24     parameter num: 7872     shape: torch.Size([41, 192])\n",
      "Layer: 25     parameter num: 41     shape: torch.Size([41])\n",
      "Total parameters num: 558569\n",
      "Layer: 0     parameter num: 41     shape: torch.Size([41])\n",
      "Layer: 1     parameter num: 41     shape: torch.Size([41])\n",
      "Layer: 2     parameter num: 1681     shape: torch.Size([41, 41])\n",
      "Total parameters num: 1763\n"
     ]
    }
   ],
   "source": [
    "# fix random seed\n",
    "same_seeds(seed)\n",
    "\n",
    "# create model, define a loss function, and optimizer\n",
    "#model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
    "#model = BiLSTM_CRF().to(device)\n",
    "bilstm = BiLSTM().to(device)\n",
    "crf = Crf().to(device)\n",
    "optimizer1 = torch.optim.AdamW(bilstm.parameters(), lr=learning_rate*20, weight_decay=0.015)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer1, \n",
    "                                        T_0=8, T_mult=2, eta_min=learning_rate/2)\n",
    "\n",
    "optimizer2  = torch.optim.AdamW(crf.parameters(), lr=learning_rate*500, weight_decay=1e-8)\n",
    "\n",
    "total_num = 0\n",
    "for i, param in enumerate(bilstm.parameters()):\n",
    "    print('Layer:', i, '    parameter num:',param.numel(), '    shape:', param.shape)\n",
    "    total_num += param.numel()\n",
    "\n",
    "print(f'Total parameters num: {total_num}')\n",
    "\n",
    "total_num = 0\n",
    "for i, param in enumerate(crf.parameters()):\n",
    "    print('Layer:', i, '    parameter num:',param.numel(), '    shape:', param.shape)\n",
    "    total_num += param.numel()\n",
    "\n",
    "print(f'Total parameters num: {total_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4433db8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T14:35:09.077399Z",
     "iopub.status.busy": "2022-03-20T14:35:09.076495Z",
     "iopub.status.idle": "2022-03-20T16:11:22.450792Z",
     "shell.execute_reply": "2022-03-20T16:11:22.450301Z",
     "shell.execute_reply.started": "2022-03-20T04:57:51.185242Z"
    },
    "papermill": {
     "duration": 5773.534974,
     "end_time": "2022-03-20T16:11:22.450921",
     "exception": false,
     "start_time": "2022-03-20T14:35:08.915947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: 1/50:   0%|                                                                       | 0/1228 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/TensorCompare.cpp:255.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
      "T: 1/50: 100%|████████████████████████████| 1228/1228 [02:15<00:00,  9.06it/s, lr1=0.002, lr2=0.05, loss=7.92]\n",
      "V: 1/50: 100%|█████████████████████████████████████████████████| 64/64 [00:53<00:00,  1.20it/s, val acc=0.751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with acc 0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: 2/50: 100%|██████████████████████████| 1228/1228 [02:14<00:00,  9.11it/s, lr1=0.00193, lr2=0.05, loss=5.87]\n",
      "V: 2/50: 100%|█████████████████████████████████████████████████| 64/64 [00:52<00:00,  1.21it/s, val acc=0.765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with acc 0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: 3/50: 100%|███████████████████████████| 1228/1228 [02:15<00:00,  9.06it/s, lr1=0.00171, lr2=0.05, loss=5.6]\n",
      "V: 3/50: 100%|█████████████████████████████████████████████████| 64/64 [00:54<00:00,  1.18it/s, val acc=0.778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with acc 0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: 4/50: 100%|███████████████████████████| 1228/1228 [02:19<00:00,  8.78it/s, lr1=0.0014, lr2=0.05, loss=5.44]\n",
      "V: 4/50: 100%|█████████████████████████████████████████████████| 64/64 [00:54<00:00,  1.17it/s, val acc=0.782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with acc 0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: 5/50: 100%|██████████████████████████| 1228/1228 [02:20<00:00,  8.76it/s, lr1=0.00103, lr2=0.05, loss=5.32]\n",
      "V: 5/50: 100%|█████████████████████████████████████████████████| 64/64 [00:56<00:00,  1.14it/s, val acc=0.785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with acc 0.785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: 6/50: 100%|█████████████████████████| 1228/1228 [02:17<00:00,  8.95it/s, lr1=0.000652, lr2=0.05, loss=5.24]\n",
      "V: 6/50: 100%|█████████████████████████████████████████████████| 64/64 [00:54<00:00,  1.17it/s, val acc=0.785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with acc 0.785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: 7/50: 100%|█████████████████████████| 1228/1228 [02:17<00:00,  8.96it/s, lr1=0.000336, lr2=0.05, loss=5.18]\n",
      "V: 7/50: 100%|█████████████████████████████████████████████████| 64/64 [00:55<00:00,  1.15it/s, val acc=0.785]\n",
      "T: 8/50: 100%|█████████████████████████| 1228/1228 [02:16<00:00,  8.99it/s, lr1=0.000124, lr2=0.05, loss=5.14]\n",
      "V: 8/50: 100%|██████████████████████████████████████████████████| 64/64 [00:53<00:00,  1.20it/s, val acc=0.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with acc 0.790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: 9/50: 100%|████████████████████████████| 1228/1228 [02:19<00:00,  8.78it/s, lr1=0.002, lr2=0.05, loss=5.29]\n",
      "V: 9/50: 100%|█████████████████████████████████████████████████| 64/64 [00:56<00:00,  1.14it/s, val acc=0.784]\n",
      "T: 10/50: 100%|█████████████████████████| 1228/1228 [02:19<00:00,  8.81it/s, lr1=0.00198, lr2=0.05, loss=5.25]\n",
      "V: 10/50: 100%|████████████████████████████████████████████████| 64/64 [00:56<00:00,  1.14it/s, val acc=0.782]\n",
      "T: 11/50: 100%|██████████████████████████| 1228/1228 [02:17<00:00,  8.92it/s, lr1=0.00193, lr2=0.05, loss=5.2]\n",
      "V: 11/50: 100%|████████████████████████████████████████████████| 64/64 [00:51<00:00,  1.23it/s, val acc=0.784]\n",
      "T: 12/50: 100%|█████████████████████████| 1228/1228 [02:19<00:00,  8.80it/s, lr1=0.00184, lr2=0.05, loss=5.15]\n",
      "V: 12/50: 100%|████████████████████████████████████████████████| 64/64 [00:56<00:00,  1.14it/s, val acc=0.781]\n",
      "T: 13/50: 100%|█████████████████████████| 1228/1228 [02:18<00:00,  8.84it/s, lr1=0.00171, lr2=0.05, loss=5.11]\n",
      "V: 13/50: 100%|████████████████████████████████████████████████| 64/64 [00:51<00:00,  1.24it/s, val acc=0.786]\n",
      "T: 14/50: 100%|█████████████████████████| 1228/1228 [02:17<00:00,  8.92it/s, lr1=0.00157, lr2=0.05, loss=5.07]\n",
      "V: 14/50: 100%|████████████████████████████████████████████████| 64/64 [00:58<00:00,  1.09it/s, val acc=0.784]\n",
      "T: 15/50: 100%|██████████████████████████| 1228/1228 [02:19<00:00,  8.81it/s, lr1=0.0014, lr2=0.05, loss=5.03]\n",
      "V: 15/50: 100%|████████████████████████████████████████████████| 64/64 [00:52<00:00,  1.23it/s, val acc=0.785]\n",
      "T: 16/50: 100%|█████████████████████████| 1228/1228 [02:19<00:00,  8.79it/s, lr1=0.00122, lr2=0.05, loss=4.99]\n",
      "V: 16/50: 100%|████████████████████████████████████████████████| 64/64 [00:51<00:00,  1.24it/s, val acc=0.791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with acc 0.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: 17/50: 100%|█████████████████████████| 1228/1228 [02:17<00:00,  8.94it/s, lr1=0.00103, lr2=0.05, loss=4.95]\n",
      "V: 17/50: 100%|████████████████████████████████████████████████| 64/64 [00:59<00:00,  1.07it/s, val acc=0.786]\n",
      "T: 18/50: 100%|████████████████████████| 1228/1228 [02:17<00:00,  8.90it/s, lr1=0.000835, lr2=0.05, loss=4.92]\n",
      "V: 18/50: 100%|████████████████████████████████████████████████| 64/64 [00:51<00:00,  1.25it/s, val acc=0.788]\n",
      "T: 19/50: 100%|████████████████████████| 1228/1228 [02:17<00:00,  8.90it/s, lr1=0.000652, lr2=0.05, loss=4.89]\n",
      "V: 19/50: 100%|████████████████████████████████████████████████| 64/64 [00:52<00:00,  1.23it/s, val acc=0.785]\n",
      "T: 20/50: 100%|████████████████████████| 1228/1228 [02:21<00:00,  8.68it/s, lr1=0.000483, lr2=0.05, loss=4.86]\n",
      "V: 20/50: 100%|████████████████████████████████████████████████| 64/64 [01:00<00:00,  1.05it/s, val acc=0.791]\n",
      "T: 21/50: 100%|████████████████████████| 1228/1228 [02:21<00:00,  8.68it/s, lr1=0.000336, lr2=0.05, loss=4.83]\n",
      "V: 21/50: 100%|████████████████████████████████████████████████| 64/64 [00:51<00:00,  1.24it/s, val acc=0.793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with acc 0.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: 22/50: 100%|████████████████████████| 1228/1228 [02:18<00:00,  8.88it/s, lr1=0.000214, lr2=0.05, loss=4.81]\n",
      "V: 22/50: 100%|████████████████████████████████████████████████| 64/64 [00:51<00:00,  1.23it/s, val acc=0.794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with acc 0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T: 23/50: 100%|█████████████████████████| 1228/1228 [02:18<00:00,  8.86it/s, lr1=0.000124, lr2=0.05, loss=4.8]\n",
      "V: 23/50: 100%|█████████████████████████████████████████████████| 64/64 [00:51<00:00,  1.24it/s, val acc=0.79]\n",
      "T: 24/50: 100%|█████████████████████████| 1228/1228 [02:19<00:00,  8.83it/s, lr1=6.87e-5, lr2=0.05, loss=4.79]\n",
      "V: 24/50: 100%|████████████████████████████████████████████████| 64/64 [00:51<00:00,  1.24it/s, val acc=0.793]\n",
      "T: 25/50: 100%|██████████████████████████████| 1228/1228 [02:13<00:00,  9.19it/s, lr1=0.002, lr2=0.05, loss=5]\n",
      "V: 25/50: 100%|████████████████████████████████████████████████| 64/64 [00:57<00:00,  1.11it/s, val acc=0.785]\n",
      "T: 26/50: 100%|██████████████████████████████| 1228/1228 [02:16<00:00,  8.99it/s, lr1=0.002, lr2=0.05, loss=5]\n",
      "V: 26/50: 100%|████████████████████████████████████████████████| 64/64 [00:51<00:00,  1.24it/s, val acc=0.783]\n",
      "T: 27/50: 100%|█████████████████████████| 1228/1228 [02:22<00:00,  8.62it/s, lr1=0.00198, lr2=0.05, loss=4.99]\n",
      "V: 27/50: 100%|████████████████████████████████████████████████| 64/64 [00:51<00:00,  1.23it/s, val acc=0.785]\n",
      "T: 28/50: 100%|█████████████████████████| 1228/1228 [02:13<00:00,  9.19it/s, lr1=0.00196, lr2=0.05, loss=4.97]\n",
      "V: 28/50: 100%|████████████████████████████████████████████████| 64/64 [01:04<00:00,  1.01s/it, val acc=0.787]\n",
      "T: 29/50: 100%|█████████████████████████| 1228/1228 [02:13<00:00,  9.19it/s, lr1=0.00193, lr2=0.05, loss=4.96]\n",
      "V: 29/50: 100%|████████████████████████████████████████████████| 64/64 [00:51<00:00,  1.24it/s, val acc=0.785]\n",
      "T: 30/50: 100%|█████████████████████████| 1228/1228 [02:21<00:00,  8.68it/s, lr1=0.00188, lr2=0.05, loss=4.94]\n",
      "V: 30/50: 100%|████████████████████████████████████████████████| 64/64 [00:51<00:00,  1.24it/s, val acc=0.783]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, model not improving, early stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "early_stop_count = 0\n",
    "for epoch in range(num_epoch):\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    train_item =0\n",
    "    # training\n",
    "    bilstm.train() # set the model to training mode\n",
    "    crf.train()\n",
    "    pbar = tqdm(train_loader, ncols=110)\n",
    "    pbar.set_description(f'T: {epoch+1}/{num_epoch}')\n",
    "    samples = 0\n",
    "    for i, batch in enumerate(pbar):\n",
    "        features, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer1.zero_grad() \n",
    "        optimizer2.zero_grad()\n",
    "        loss = -crf.likelihood(bilstm(features), labels)\n",
    "        loss.backward()\n",
    "        grad_norm = nn.utils.clip_grad_norm_(bilstm.parameters(), max_norm=50)\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_item += labels.size(0)\n",
    "        \n",
    "        lr1 = optimizer1.param_groups[0][\"lr\"]\n",
    "        lr2 = optimizer2.param_groups[0][\"lr\"]\n",
    "        pbar.set_postfix({'lr1':lr1, 'lr2':lr2, 'loss':train_loss/train_item})\n",
    "    scheduler.step()\n",
    "    pbar.close()\n",
    "    # validation\n",
    "    if len(val_set) > 0:\n",
    "        bilstm.eval() # set the model to evaluation mode\n",
    "        crf.eval()\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(val_loader, ncols=110)\n",
    "            pbar.set_description(f'V: {epoch+1}/{num_epoch}')\n",
    "            samples = 0\n",
    "            for i, batch in enumerate(pbar):\n",
    "                features, labels = batch\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = crf(bilstm(features))                \n",
    "                val_acc += (outputs[:, mid] == labels[:, mid].cpu()).sum().item()\n",
    "                samples += labels.size(0)\n",
    "                pbar.set_postfix({'val acc':val_acc/samples})\n",
    "            pbar.close()\n",
    "            # if the model improves, save a checkpoint at this epoch\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(bilstm.state_dict(), model1_path)\n",
    "            torch.save(crf.state_dict(), model2_path)\n",
    "            print('saving model with acc {:.3f}'.format(best_acc/(len(val_set))))\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "            if early_stop_count >= early_stopping:\n",
    "                print(f\"Epoch: {epoch + 1}, model not improving, early stopping.\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f84e971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T16:12:13.496459Z",
     "iopub.status.busy": "2022-03-20T16:12:13.495744Z",
     "iopub.status.idle": "2022-03-20T16:12:13.498971Z",
     "shell.execute_reply": "2022-03-20T16:12:13.499375Z",
     "shell.execute_reply.started": "2022-03-20T04:58:20.790088Z"
    },
    "papermill": {
     "duration": 25.35355,
     "end_time": "2022-03-20T16:12:13.499521",
     "exception": false,
     "start_time": "2022-03-20T16:11:48.145971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_loader, val_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b9e0b2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T16:13:03.718954Z",
     "iopub.status.busy": "2022-03-20T16:13:03.718175Z",
     "iopub.status.idle": "2022-03-20T16:13:16.306146Z",
     "shell.execute_reply": "2022-03-20T16:13:16.306567Z",
     "shell.execute_reply.started": "2022-03-20T04:58:21.70129Z"
    },
    "papermill": {
     "duration": 38.047038,
     "end_time": "2022-03-20T16:13:16.306787",
     "exception": false,
     "start_time": "2022-03-20T16:12:38.259749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] - # phone classes: 41, number of utterances for test: 1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1078it [00:12, 86.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test set\n",
      "torch.Size([646268, 819])\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "test_X = preprocess_data(split='test', feat_dir='../input/ml2022spring-hw2/libriphone/libriphone/feat',\n",
    "                         phone_path='../input/ml2022spring-hw2/libriphone/libriphone', concat_nframes=concat_nframes)\n",
    "\n",
    "test_set = LibriDataset(test_X)\n",
    "\n",
    "import gc\n",
    "del test_X\n",
    "gc.collect()\n",
    "\n",
    "# get dataloader\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95bb2386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T16:14:06.512490Z",
     "iopub.status.busy": "2022-03-20T16:14:06.511614Z",
     "iopub.status.idle": "2022-03-20T16:14:06.536433Z",
     "shell.execute_reply": "2022-03-20T16:14:06.536866Z",
     "shell.execute_reply.started": "2022-03-20T04:58:32.757859Z"
    },
    "papermill": {
     "duration": 25.39122,
     "end_time": "2022-03-20T16:14:06.537018",
     "exception": false,
     "start_time": "2022-03-20T16:13:41.145798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "#model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
    "bilstm = BiLSTM().to(device)\n",
    "bilstm.load_state_dict(torch.load(model1_path))\n",
    "\n",
    "crf = Crf().to(device)\n",
    "crf.load_state_dict(torch.load(model2_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "623a25e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T16:14:57.241164Z",
     "iopub.status.busy": "2022-03-20T16:14:57.240329Z",
     "iopub.status.idle": "2022-03-20T16:19:31.199601Z",
     "shell.execute_reply": "2022-03-20T16:19:31.183777Z",
     "shell.execute_reply.started": "2022-03-20T04:58:36.131737Z"
    },
    "papermill": {
     "duration": 299.248531,
     "end_time": "2022-03-20T16:19:31.199767",
     "exception": false,
     "start_time": "2022-03-20T16:14:31.951236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [04:20<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([], dtype=np.int32)\n",
    "\n",
    "bilstm.eval()\n",
    "crf.eval()\n",
    "with torch.no_grad():\n",
    "    for features in tqdm(test_loader):\n",
    "        features = features.to(device)\n",
    "        outputs = crf(bilstm(features))\n",
    "        pred = np.concatenate((pred, outputs.detach().cpu()[:, mid]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2af95729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T16:20:21.227511Z",
     "iopub.status.busy": "2022-03-20T16:20:21.225151Z",
     "iopub.status.idle": "2022-03-20T16:20:22.129058Z",
     "shell.execute_reply": "2022-03-20T16:20:22.130176Z",
     "shell.execute_reply.started": "2022-03-20T04:53:50.997651Z"
    },
    "papermill": {
     "duration": 25.657883,
     "end_time": "2022-03-20T16:20:22.130383",
     "exception": false,
     "start_time": "2022-03-20T16:19:56.472500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('prediction.csv', 'w') as f:\n",
    "    f.write('Id,Class\\n')\n",
    "    for i, y in enumerate(pred):\n",
    "        f.write('{},{}\\n'.format(i, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6416.595689,
   "end_time": "2022-03-20T16:20:49.274366",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-20T14:33:52.678677",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
